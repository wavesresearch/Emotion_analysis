{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import openpyxl\n",
    "import re\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "channels=62\n",
    "drive='E'\n",
    "entropy='diff_entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath=drive+r'feature matrix address'\n",
    "file = os.listdir(mypath)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file='label address'\n",
    "label_fname = os.path.join(mypath,label_file)\n",
    "label = np.load(label_fname,allow_pickle='TRUE')\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "std_list = []\n",
    "f1_score_acc_list = []\n",
    "f1_score_std_list = []\n",
    "all_acc = []\n",
    "all_f1_score = []\n",
    "num_classes=3\n",
    "folds=5\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "for i in range(2):\n",
    "for i in range(len(file_feat)):\n",
    "    data_fname = os.path.join(mypath,file_feat[i])\n",
    "    data = np.load(data_fname,allow_pickle='TRUE')\n",
    "    data1=data.reshape(data.shape[0],data.shape[1]*data.shape[2])\n",
    "    ##########################\n",
    "    ##############################\n",
    "    y_label = label\n",
    "    y_label = to_categorical(y_label, num_classes)\n",
    "    feat_data = data1\n",
    "    print(y_label.shape)\n",
    "    print(f'feat_data shape is:{feat_data.shape}')\n",
    "    ############################\n",
    "    kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=5)\n",
    "    # create model\n",
    "    for train, test in kfold.split(feat_data, y_label.argmax(1)):\n",
    "        x_train = feat_data[train]\n",
    "        y_train = y_label[train]\n",
    "        x_in=keras.Input(shape=(x_train.shape[1],))\n",
    "        x = Dense(256, activation='relu')(x_in)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        out_layer = Dense(3, activation='softmax', name='out')(x)\n",
    "        model = keras.Model(x_in, out_layer)\n",
    "#         model.summary()\n",
    "        # Compile model\n",
    "#         loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "#         loss_fn = keras.losses.categorical_crossentropy()\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "        # Fit the model\n",
    "        model.fit(x_train, y_train, epochs=100, batch_size=128, verbose=0)\n",
    "        # evaluate the model\n",
    "        x_test = feat_data[test]\n",
    "        y_test = y_label[test]\n",
    "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "        #############\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_true=y_test\n",
    "        y_pred=np.argmax(y_pred, axis=1)\n",
    "        y_true=np.argmax(y_true, axis=1)\n",
    "        # precision=metrics.precision_score(y_true, y_pred, average='macro')\n",
    "        # recall=metrics.recall_score(y_true, y_pred, average='macro')\n",
    "        f1_score=metrics.f1_score(y_true, y_pred, average='macro')\n",
    "        all_acc.append(scores[1] * 100)\n",
    "        all_f1_score.append(f1_score)\n",
    "        #############\n",
    "    acc_list.append(np.mean(all_acc))\n",
    "    std_list.append(np.std(all_acc))\n",
    "    f1_score_acc_list.append(np.mean(all_f1_score))\n",
    "    f1_score_std_list.append(np.std(all_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame()\n",
    "results['Acc_all']=acc_list\n",
    "results['Std_all']=std_list\n",
    "results['f1_score_acc']=f1_score_acc_list\n",
    "results['f1_score_std']=f1_score_std_list\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
